# Vietnamese E-commerce Dialog-based Multimodal Retrieval Framework

**Reference Implementation for Research Paper**: _"A Dialogue-based Multimodal Retrieval Framework for Vietnamese E-commerce RAG System"_

âš ï¸ **Important Notice**: This codebase has been refactored from original Google Colab notebooks for reference purposes. While the architecture and implementation follow the paper specifications, it may require additional setup and debugging to run successfully. Use this primarily as a reference for understanding the methodology, functions, classes, and system architecture.

## ğŸ“„ Paper Overview

This repository implements a complete 3-module architecture for Vietnamese e-commerce product retrieval using dialog-based interactions:

1. **Attribute Predictor** - Multi-label prediction on product attributes
2. **Product Captioner** - Generates comparative captions between products
3. **Dialog-based Retriever** - Contextualized late interaction for token-level matching

### Key Contributions

- **Contextualized Late Interaction**: Token-level fidelity preservation with modality-aware scoring
- **Two-stage Training**: Warm-up + fine-tuning for stable multimodal alignment
- **Vietnamese E-commerce Focus**: Handles code-mixed text, missing diacritics, inconsistent taxonomies
- **Production-ready Pipeline**: Single query-side pass without costly reranking

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Attribute       â”‚    â”‚ Product         â”‚    â”‚ Dialog-based    â”‚
â”‚ Predictor       â”‚â”€â”€â”€â–¶â”‚ Captioner       â”‚â”€â”€â”€â–¶â”‚ Retriever       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ EfficientNet/   â”‚    â”‚ Comparative     â”‚    â”‚ Late Interactionâ”‚
â”‚ Swin + Linear   â”‚    â”‚ Caption Gen     â”‚    â”‚ + Qwen2-VL-2B   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ main.py                          # Complete training pipeline
â”œâ”€â”€ requirements.txt                 # Dependencies
â”œâ”€â”€ README.md                       # This file
â”‚
â”œâ”€â”€ attribute_predictor/            # Module 1: Attribute Prediction
â”‚   â”œâ”€â”€ __init__.py                 # Module exports
â”‚   â”œâ”€â”€ dataset.py                  # ProductImageDataset class
â”‚   â””â”€â”€ train.py                    # Training with early stopping
â”‚
â”œâ”€â”€ captioner/                      # Module 2: Product Captioner
â”‚   â”œâ”€â”€ __init__.py                 # Module exports
â”‚   â”œâ”€â”€ model.py                    # ProductCaptioningModel
â”‚   â”œâ”€â”€ dataset.py                  # CaptioningDataset
â”‚   â”œâ”€â”€ train.py                    # Training with nucleus sampling
â”‚   â”œâ”€â”€ evaluation.py               # BLEU/ROUGE/CIDEr metrics
â”‚   â”œâ”€â”€ data_preparation.py         # Complete data prep pipeline
â”‚   â”œâ”€â”€ prepare_data.py            # Original tokenization (reference)
â”‚   â””â”€â”€ prepare_image_pairs.py     # Original pair generation (reference)
â”‚
â”œâ”€â”€ retriever/                      # Module 3: Dialog-based Retriever
â”‚   â”œâ”€â”€ __init__.py                 # Module exports
â”‚   â”œâ”€â”€ model.py                    # QwenVLTripletEncoder + Late Interaction
â”‚   â”œâ”€â”€ dataloader.py              # Triplet data loading
â”‚   â”œâ”€â”€ train.py                    # Two-stage training pipeline
â”‚   â””â”€â”€ evaluation.py              # MRR/Recall@k/Dialog metrics
â”‚
â””â”€â”€ data/                          # Dataset (to be uploaded)
    â”œâ”€â”€ attributes.json            # Product attribute labels
    â”œâ”€â”€ captioner_pairs.json      # Product pairs for captioning
    â”œâ”€â”€ wcaptions.json            # Dialog captions data
    â””â”€â”€ images/                   # Product images
```

## ğŸ”§ Implementation Details

### Attribute Predictor

- **Backbones**: EfficientNet-B0/B4, Swin Transformer
- **Task**: Multi-label classification on Vietnamese product attributes
- **Evaluation**: Precision/Recall/F1 (macro-averaged)

### Product Captioner

- **Architecture**: Visual features + Attribute vectors â†’ LSTM decoder
- **Training**: Teacher forcing + attribute consistency loss
- **Output**: Short Vietnamese comparative captions (â‰¤20 words)

### Dialog-based Retriever

- **Base Model**: Qwen2-VL-2B-Instruct
- **Late Interaction**: Token-level max-similarity scoring
- **Training**: Two-stage (warm-up â†’ multi-turn fine-tuning)
- **Modes**: Pooled embeddings vs. Late interaction comparison

## ğŸ“Š Expected Performance

Based on paper results (Table V - Dialog-based retrieval performance with EfficientNet B0 as captioner backbone):

**Offline Retrieval Metrics**:

- **MRR**: 0.663
- **Recall@1**: 0.475
- **Recall@5**: 0.915
- **nDCG@10**: 0.743

**Online Multi-turn Success**:

- **Dialog@â‰¤1**: 0.35 (35% success within 1 turn)
- **Dialog@â‰¤3**: 0.45 (45% success within 3 turns)
- **Dialog@â‰¤5**: 0.65 (65% success within 5 turns)
- **Mean Turns**: 3.41

_Model: Contextualized Retriever with Late Interaction_

## ğŸš€ Quick Start

### Installation

```bash
pip install -r requirements.txt
```

### Usage Examples

**Complete Pipeline**:

```bash
python main.py --stage all --output_dir outputs/
```

**Individual Stages**:

```bash
# Stage 1: Attribute Predictor
python main.py --stage attribute

# Stage 2: Product Captioner
python main.py --stage captioner

# Stage 3: Dialog Retriever
python main.py --stage retriever

# Stage 4: Evaluation
python main.py --stage evaluation
```

**Custom Configuration**:

```bash
python main.py --config config.json --debug
```

### Configuration

The `create_default_config()` function in `main.py` provides all configurable parameters:

```python
config = {
    "attribute_backbones": ["efficientnet-b0", "efficientnet-b4", "swin"],
    "qwen_model_name": "Qwen/Qwen2-VL-2B-Instruct",
    "enable_late_interaction": True,
    "token_dim": 128,
    "late_interaction_mode": "context",  # or "modality_wise"
    # ... more parameters
}
```

## ğŸ“š Key Classes and Functions

### Attribute Predictor

```python
from attribute_predictor import ProductImageDataset, train_with_early_stopping

# Dataset with image loading and caching
dataset = ProductImageDataset(df, cache_dir="./cache")

# Training with multiple backbones
model = train_with_early_stopping(model, train_loader, val_loader, ...)
```

### Product Captioner

```python
from captioner import ProductCaptioningModel, CaptioningDataset

# Comparative captioning model
model = ProductCaptioningModel(
    backbone="efficientnet-b4",
    vocab_size=736,
    attr_vocab_size=1355
)

# Training with nucleus sampling
train_product_captioning_model(model, train_loader, val_loader, ...)
```

### Dialog-based Retriever

```python
from retriever import QwenVLTripletEncoder, split_wcaptions_dataset

# Late interaction encoder
model = QwenVLTripletEncoder(
    model_name="Qwen/Qwen2-VL-2B-Instruct",
    enable_late_interaction=True,
    token_dim=128
)

# Two-stage training
train_qwen_triplet_retriever(model, train_loader, val_loader, ...)
```

## ğŸ“Š Data Format

### Attributes Data (`attributes.json`)

```json
{
  "product_id": "12345",
  "image_url": "path/to/image.jpg",
  "attributes": ["red", "A-line", "cotton", "short-sleeve"],
  "title": "VÃ¡y A-line mÃ u Ä‘á» tay ngáº¯n"
}
```

### Captions Data (`wcaptions.json`)

```json
{
  "Ir_path": "path/to/reference.jpg",
  "It_path": "path/to/target.jpg",
  "caption": "nhÆ° cÃ¡i nÃ y nhÆ°ng mÃ u xanh vÃ  tay dÃ i hÆ¡n",
  "Ir_attributes": ["red", "short-sleeve"],
  "It_attributes": ["blue", "long-sleeve"]
}
```

## âš ï¸ Known Limitations

1. **Dataset Dependency**: Requires Vietnamese e-commerce product data (being processed)
2. **Model Compatibility**: May need adjustments for different PyTorch/Transformers versions
3. **GPU Requirements**: Qwen2-VL-2B requires significant GPU memory
4. **Language Models**: Some Vietnamese text processing may need fine-tuning

## ğŸ”¬ Research Use

This codebase is designed for:

- **Understanding** the paper's methodology and architecture
- **Reproducing** experiments with proper dataset
- **Extending** to other languages or domains
- **Benchmarking** against the proposed approach

## ğŸ“– Citation

If you use this code for research, please cite the original paper:

```bibtex
@article{vietnamese_ecommerce_rag_2024,
  title={A Dialogue-based Multimodal Retrieval Framework for Vietnamese E-commerce RAG System},
  author={Ho Ngoc Tuong Vy, Ngo Thuan Phat, Nguyen Huynh Minh Huy, Nguyen Minh Nhut, Nguyen Dinh Thuan},
  year={2024},
  institution={University of Information Technology, VNU-HCM}
}
```

## ğŸ“„ License

This research code is provided for academic and research purposes. Please check with the original authors for commercial usage rights.

## ğŸ”„ Updates

- **Dataset**: Currently being processed and will be uploaded soon
- **Documentation**: Additional tutorials and examples coming
- **Compatibility**: Testing with latest library versions in progress

---

**Note**: This is a reference implementation refactored from research notebooks. For production use, additional engineering and testing would be required.
